{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Change it to the project root path \"\"\"\n",
    "PROJECT_PATH = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchquad import  enable_cuda, VEGAS\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = 1\n",
    "dataset_name = 'power'\n",
    "\n",
    "\"\"\" network parameters \"\"\"\n",
    "hidden_features = 108\n",
    "num_flow_steps = 6\n",
    "\n",
    "flow_id = 1\n",
    "\n",
    "features = 6\n",
    "\n",
    "REUSE_FROM_FILE = True\n",
    "REUSE_FILE_PATH = PROJECT_PATH + 'train/'\n",
    "\n",
    "\"\"\" query settings\"\"\"\n",
    "query_seed = 55\n",
    "QUERY_CNT = 2000\n",
    "\n",
    "\"\"\" detailed network parameters\"\"\"\n",
    "anneal_learning_rate = True\n",
    "base_transform_type = 'rq-coupling'\n",
    "\n",
    "dropout_probability = 0\n",
    "grad_norm_clip_value = 5.\n",
    "linear_transform_type='lu'\n",
    "\n",
    "num_bins = 8\n",
    "num_training_steps = 400000\n",
    "num_transform_blocks = 2\n",
    "seed = 1638128\n",
    "tail_bound = 3\n",
    "use_batch_norm = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataUtils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnflows\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flows\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnflows\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn_\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdataUtils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mut\u001b[39;00m\n\u001b[1;32m     40\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     41\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataUtils'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, sys\n",
    "\n",
    "\"\"\" set GPU first \"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(GPU_ID)\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from time import sleep\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "sys.path.append('../FACE_utils/')\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from nflows import transforms\n",
    "from nflows import distributions\n",
    "from nflows import utils\n",
    "from nflows import flows\n",
    "import nflows.nn as nn_\n",
    "\n",
    "\n",
    "\n",
    "import dataUtils as ut\n",
    "\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "DEVICENAME = torch.cuda.get_device_name(0)\n",
    "print('DEVICE NAME\\n', DEVICENAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_transform():\n",
    "    if linear_transform_type == 'permutation':\n",
    "        return transforms.RandomPermutation(features=features)\n",
    "    elif linear_transform_type == 'lu':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.LULinear(features, identity_init=True)\n",
    "        ])\n",
    "    elif linear_transform_type == 'svd':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.SVDLinear(features, num_householder=10, identity_init=True)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def create_base_transform(i):\n",
    "    # tmp_mask = utils.create_alternating_binary_mask(features, even=(i % 2 == 0))\n",
    "    return transforms.coupling.PiecewiseRationalQuadraticCouplingTransform(\n",
    "        mask=utils.create_alternating_binary_mask(features, even=(i % 2 == 0)),\n",
    "        transform_net_create_fn=lambda in_features, out_features: nn_.nets.ResidualNet(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            hidden_features=hidden_features,\n",
    "            context_features=None,\n",
    "            num_blocks=num_transform_blocks,\n",
    "            activation=F.relu,\n",
    "            dropout_probability=dropout_probability,\n",
    "            use_batch_norm=use_batch_norm\n",
    "        ),\n",
    "        num_bins=num_bins,\n",
    "        tails='linear',\n",
    "        tail_bound=tail_bound,\n",
    "        apply_unconditional_transform=True\n",
    "    )\n",
    "\n",
    "\n",
    "# torch.masked_select()\n",
    "def create_transform():\n",
    "    transform = transforms.CompositeTransform([\n",
    "        transforms.CompositeTransform([\n",
    "            create_linear_transform(),\n",
    "            create_base_transform(i)\n",
    "        ]) for i in range(num_flow_steps)\n",
    "    ] + [\n",
    "        create_linear_transform()\n",
    "    ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 330954 trainable parameters in this model.\n",
      "Parameters total size is 1.2624893188476562 MB\n"
     ]
    }
   ],
   "source": [
    "distribution = distributions.StandardNormal((features,))\n",
    "transform = create_transform()\n",
    "flow = flows.Flow(transform, distribution).to(device)\n",
    "\n",
    "\n",
    "# if 'Ti' in DEVICENAME:\n",
    "#     path = os.path.join(PROJECT_PATH+'train/models/{}'.format(dataset_name),\n",
    "#                         '{}-id{}-best-val.t'.format(dataset_name, flow_id))\n",
    "\n",
    "# else:\n",
    "#     assert False\n",
    "\n",
    "path = os.path.join(PROJECT_PATH+'train/models/{}'.format(dataset_name),\n",
    "                        '{}-id{}-best-val.t'.format(dataset_name, flow_id))\n",
    "\n",
    "flow.load_state_dict(torch.load(path))\n",
    "\n",
    "flow.cuda()\n",
    "flow.eval()\n",
    "\n",
    "\n",
    "n_params = utils.get_num_parameters(flow)\n",
    "print('There are {} trainable parameters in this model.'.format(n_params))\n",
    "print('Parameters total size is {} MB'.format(n_params * 4 / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DataWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (2049280, 6)\n"
     ]
    }
   ],
   "source": [
    "data, n, dim = ut.LoadTable(dataset_name)\n",
    "DW = ut.DataWrapper(data, dataset_name)\n",
    "rng = np.random.RandomState(query_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save oracle results to :\n",
      "../evaluate/oracle/power_rng-55.csv\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(query_seed)\n",
    "queries = DW.generateNQuery(2000, rng)\n",
    "DW.getAndSaveOracle(queries, query_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found oracle card!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load oracle_cards\"\"\"\n",
    "oracle_cards = ut.LoadOracleCardinalities(dataset_name, query_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_lists = DW.getLegalRangeNQuery(queries)\n",
    "legal_tensors = torch.Tensor(legal_lists).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchquad import set_up_backend\n",
    "set_up_backend(\"torch\", data_type=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" q-error \"\"\"\n",
    "def ErrorMetric(est_card, card):\n",
    "    if isinstance(est_card, torch.FloatTensor) or isinstance(est_card, torch.IntTensor):\n",
    "        est_card = est_card.cpu().detach().numpy()\n",
    "    if isinstance(est_card, torch.Tensor):\n",
    "        est_card = est_card.cpu().detach().numpy()\n",
    "    est_card = np.float32(est_card)\n",
    "    card = np.float32(card)\n",
    "    if card == 0 and est_card != 0:\n",
    "        return est_card\n",
    "    if card != 0 and est_card == 0:\n",
    "        return card\n",
    "    if card == 0 and est_card == 0:\n",
    "        return 1.0\n",
    "    return max(est_card / card, card / est_card)\n",
    "\n",
    "def BatchErrorMetrix(est_list, oracle_list):\n",
    "    ret = np.zeros(len(est_list))\n",
    "    ID = 0\n",
    "    for est, real in zip(est_list, oracle_list):\n",
    "        ret[ID] = ErrorMetric(est, real)\n",
    "        ID = ID + 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_batch_time = 0\n",
    "def f_batch(inp):\n",
    "    global f_batch_time\n",
    "    with torch.no_grad():\n",
    "        inp = inp.cuda()\n",
    "\n",
    "        print(\"【Example input】\", inp[0,:])\n",
    "        print(\"inp shape \", inp.shape)\n",
    "        st = time.time()\n",
    "        prob_list = flow.log_prob(inp)\n",
    "        prob_list = torch.exp(prob_list)\n",
    "        print(\"【max_prob】 \",prob_list.max())\n",
    "        print(\"【median_prob】 \",prob_list.median())\n",
    "        en = time.time()\n",
    "        f_batch_time += en - st\n",
    "\n",
    "        return prob_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __init__(self, activated=True):\n",
    "        self.activated = activated\n",
    "        self.original_stdout = None\n",
    "\n",
    "    def open(self):\n",
    "        \"\"\" no output \"\"\"\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self.original_stdout\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" output \"\"\"\n",
    "        self.original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __enter__(self):\n",
    "        if self.activated:\n",
    "            self.close()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.activated:\n",
    "            self.open()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse Sampling Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# f=open('/home/jiayi/disk/FACE/map.pickle','wb')  \n",
    "# pickle.dump(target_map, f)\n",
    "if REUSE_FROM_FILE == True:\n",
    "    f=open(REUSE_FILE_PATH + '{}.pickle'.format(dataset_name),'rb')  \n",
    "    target_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "z = DW.getLegalRangeQuery([[],[],[]])\n",
    "z = torch.Tensor(z)\n",
    "print(z.shape)\n",
    "full_integration_domain = torch.Tensor(z)\n",
    "\n",
    "domain_starts = full_integration_domain[:, 0]\n",
    "domain_sizes =  full_integration_domain[:, 1] - domain_starts\n",
    "domain_volume = torch.prod(domain_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if REUSE_FROM_FILE == False:\n",
    "    vegas = VEGAS()\n",
    "    bigN = 1000000 * 40\n",
    "\n",
    "    st = time.time()\n",
    "    result = vegas.integrate(f_batch,dim=features,\n",
    "                             N=bigN,\n",
    "                             integration_domain=full_integration_domain,\n",
    "                             use_warmup=True,\n",
    "                             use_grid_improve=True,\n",
    "                             max_iterations=40\n",
    "                             )\n",
    "\n",
    "    en= time.time()\n",
    "    print(\"Took \", en-st)\n",
    "    print(result)\n",
    "    result = result * DW.n\n",
    "\n",
    "    print('result is ',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REUSE_FROM_FILE == False:\n",
    "    target_map = vegas.map\n",
    "    import pickle\n",
    "    f=open(REUSE_FILE_PATH + \"{}.pickle\".format(dataset_name),'wb')  \n",
    "    pickle.dump(target_map, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchquad import BatchMulVEGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(n, N, num_iterations=3, alpha=0.5, beta=0.5):\n",
    "    global f_batch_time\n",
    "    \"\"\" n: batch size \"\"\"\n",
    "    z = BatchMulVEGAS()\n",
    "    DIM = features\n",
    "    full_integration_domain = torch.Tensor(DIM * [[0,1]])\n",
    "    \n",
    "    start_id = 0\n",
    "    end_id = 0\n",
    "\n",
    "    f_batch_time  = 0\n",
    "    st = time.time()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        while start_id < 2000:\n",
    "            end_id = end_id + n\n",
    "            if end_id > 2000:\n",
    "                end_id = 2000\n",
    "            z.setValues(f_batch,\n",
    "                    dim=DIM,\n",
    "                    alpha=alpha,\n",
    "                    beta=beta,\n",
    "                    N=N,\n",
    "                    n=end_id - start_id,\n",
    "                    iterations=num_iterations,\n",
    "                    integration_domains=legal_tensors[start_id:end_id],\n",
    "                    rng=None,\n",
    "                    seed=234,\n",
    "                    reuse_sample_points=True,\n",
    "                    target_map=target_map,\n",
    "                    target_domain_starts = domain_starts,\n",
    "                    target_domain_sizes = domain_sizes,\n",
    "                    )\n",
    "            start_id = start_id + n\n",
    "            results.append(z.integrate())\n",
    "\n",
    "    en = time.time()\n",
    "    total_time = en-st\n",
    "    return total_time, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end-to-end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testHyper(n, N, num_iterations, alpha, beta):\n",
    "    with HiddenPrints():\n",
    "        total_time, result = getResult(n=n, \n",
    "                               N=N, \n",
    "                               num_iterations=num_iterations,\n",
    "                               alpha=alpha, \n",
    "                               beta=beta)\n",
    "    \n",
    "\n",
    "        result = torch.cat(tuple(result))\n",
    "        FULL_SIZE = torch.Tensor([DW.n])\n",
    "        result = result * FULL_SIZE\n",
    "        result = result.to('cpu')\n",
    "\n",
    "        n_ = 2000\n",
    "        oracle_list = oracle_cards.copy()\n",
    "\n",
    "        err_list = BatchErrorMetrix(result.int(), oracle_list)\n",
    "\n",
    "\n",
    "        total_query_time = total_time\n",
    "        avg_per_query_time = 1000. * (total_query_time/n_)\n",
    "        avg_f_batch_time   = 1000.* f_batch_time / n_\n",
    "        avg_vegas_time     = avg_per_query_time - avg_f_batch_time\n",
    "\n",
    "\n",
    "\n",
    "    print(\"********** total_n=[{}] batchn=[{}]  N=[{}]  nitr=[{}]  alpha=[{}]  beta=[{}] ******\".format(n_, n, N, num_iterations, alpha, beta))\n",
    "    print('@ Average per query          [{}] ms'.format(avg_per_query_time))\n",
    "    print(' --  Average per query NF    [{}] ms'.format(avg_f_batch_time))\n",
    "    print(' --  Average per query vegas [{}] ms'.format(avg_vegas_time))\n",
    "    p50 = np.percentile (err_list, 50)\n",
    "    p95 = np.percentile(err_list, 95)\n",
    "    p99 = np.percentile(err_list, 99)\n",
    "    pmax = np.max(err_list)\n",
    "    print('Median [{:.3f}]  95th [{:.3f}]  99th [{:.3f}]  max [{:.3f}]'.format(np.percentile (err_list, 50), np.percentile(err_list, 95),\n",
    "                                                               np.percentile(err_list, 99), np.max(err_list)))\n",
    "\n",
    "    return p50,p95,p99,pmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangping/anaconda3/envs/face/lib/python3.8/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at  ../aten/src/ATen/native/BucketizationUtils.h:28.)\n",
      "  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** total_n=[2000] batchn=[667]  N=[15000]  nitr=[3]  alpha=[0.6]  beta=[0.1] ******\n",
      "@ Average per query          [7.091784119606018] ms\n",
      " --  Average per query NF    [5.077221989631653] ms\n",
      " --  Average per query vegas [2.0145621299743652] ms\n",
      "Median [1.026]  95th [1.196]  99th [1.984]  max [58.111]\n"
     ]
    }
   ],
   "source": [
    "alpha_list= [0.6]\n",
    "beta_list = [0.1]\n",
    "\n",
    "p50s = []\n",
    "p95s = []\n",
    "p99s = []\n",
    "pmaxs = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    for beta in beta_list:\n",
    "        p50, p95, p99, pmax = testHyper(667, 15000, 3, alpha, beta)\n",
    "        p95s.append(p95)\n",
    "        p99s.append(p99s)\n",
    "        pmaxs.append(pmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
